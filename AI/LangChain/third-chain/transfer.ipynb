{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971bf709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  SystemMessage {\n",
       "    \"content\": \"\\n你是一个专业的翻译员，你的任务是将文本从English翻译成Chinese。\\n\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  },\n",
       "  HumanMessage {\n",
       "    \"content\": \"请翻译这句话：Hello, how are you?\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate } from '@langchain/core/prompts';\n",
    "\n",
    "\n",
    "const transferPrompt = SystemMessagePromptTemplate.fromTemplate(`\n",
    "你是一个专业的翻译员，你的任务是将文本从{source_lang}翻译成{target_lang}。\n",
    "`);\n",
    "\n",
    "const humanPrompt = HumanMessagePromptTemplate.fromTemplate(`请翻译这句话：{text}`);\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([transferPrompt, humanPrompt]);\n",
    "\n",
    "const formattedPrompt = await chatPrompt.formatMessages({\n",
    "  source_lang: 'English',\n",
    "  target_lang: 'Chinese',\n",
    "  text: 'Hello, how are you?',\n",
    "});\n",
    "\n",
    "formattedPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d5247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Hello, I am Shen Yuan.\"\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { Ollama } from \"@langchain/community/llms/ollama\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const ollama = new Ollama({\n",
    "  baseUrl: \"http://localhost:11434\", \n",
    "  model: \"qwen3-vl:4b\", \n",
    "});\n",
    "const outputPraser = new StringOutputParser();\n",
    "\n",
    "const chain = chatPrompt.pipe(ollama).pipe(outputPraser);\n",
    "\n",
    "await chain.invoke({\n",
    "  source_lang: \"中文\",\n",
    "  target_lang: \"英语\",\n",
    "  text: \"你好，我是沈渊\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef74c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Bonjour, je suis Shen Yuan.\"\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.invoke({\n",
    "  source_lang: \"中文\",\n",
    "  target_lang: \"法语\",\n",
    "  text: \"你好，我是沈渊\",\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
